package main

import (
	"crypto/sha1"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"math/rand"
	"os"
	"path/filepath"
	"testing"
	"time"
)

func TestScanForJobs(t *testing.T) {
	stop := make(chan struct{})
	defer close(stop)
	jobs := make(chan Job)

	root := filepath.Join(t.TempDir(), "data")

	files := []string{
		"node-000048b02d15bc7c/uploads/imagesampler-top/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/data",
		"node-000048b02d15bc7c/uploads/imagesampler-top/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/meta",

		"node-000048b02d15bc7c/uploads/Pluginctl/imagesampler-top/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/data",
		"node-000048b02d15bc7c/uploads/Pluginctl/imagesampler-top/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/meta",

		"node-0000000000000001/uploads/no-meta/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/data",

		"node-0000000000000002/uploads/no-data/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/meta",

		"node-0000000000000001/uploads/done/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/data",
		"node-0000000000000001/uploads/done/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/meta",
		"node-0000000000000001/uploads/done/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/.done",
	}

	for _, file := range files {
		path := filepath.Join(root, file)
		if err := os.MkdirAll(filepath.Dir(path), 0o755); err != nil {
			t.Fatal(err)
		}
		if err := os.WriteFile(path, []byte{}, 0o644); err != nil {
			t.Fatal(err)
		}
	}

	go func() {
		scanForJobs(stop, jobs, root)
		close(jobs)
	}()

	seen := make(map[Job]bool)

	for job := range jobs {
		seen[job] = true
	}

	wantDirs := []string{
		"node-000048b02d15bc7c/uploads/imagesampler-top/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c",
		"node-000048b02d15bc7c/uploads/Pluginctl/imagesampler-top/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c",
	}

	for _, dir := range wantDirs {
		job := Job{Root: root, Dir: dir}
		if !seen[job] {
			t.Fatalf("missing job for %s", dir)
		}
		delete(seen, job)
	}

	for job := range seen {
		t.Fatalf("got unexpected job: %+v", job)
	}
}

func TestFuzzWorker(t *testing.T) {
	testcases := randomWorkerTestCases(10)

	var jobs []Job

	root := filepath.Join(t.TempDir(), "data")

	for _, tc := range testcases {
		if err := tc.WriteFiles(root); err != nil {
			t.Fatal(err)
		}
		jobs = append(jobs, Job{Root: root, Dir: tc.Dir()})
	}

	// actuall use the scanForJobs here... to bind what we check to reality

	// process all the jobs
	uploader := NewMockUploader()
	worker := &Worker{Uploader: uploader}

	for _, job := range jobs {
		if err := worker.Process(job); err != nil {
			t.Fatal(err)
		}
	}

	// check that exactly these items were uploaded
	for _, tc := range testcases {
		dir := tc.Dir()

		dataSrc := filepath.Join(root, dir, "data")
		dataDst := filepath.Join("node-data", "sage", fmt.Sprintf("sage-%s-%s", tc.Task, tc.Version), tc.Node, fmt.Sprintf("%d-%s", tc.Timestamp.UnixNano(), tc.Filename))

		metaSrc := filepath.Join(root, dir, "meta")
		metaDst := dataDst + ".meta"

		if !uploader.WasUploaded(dataSrc, dataDst) {
			t.Fatalf("missing upload\nsrc: %s\ndst: %s", dir, dataDst)
		}

		if !uploader.WasUploaded(metaSrc, metaDst) {
			t.Fatalf("missing upload\nsrc: %s\ndst: %s", dir, metaDst)
		}
	}
}

// dir: "node-000048b02d15bc7c/uploads/imagesampler-top/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c",
// dst: "node-data/sage/sage-imagesampler-top-0.2.5/000048b02d15bc7c/1638576647406523064-wow1.txt",

func TestWorkerProcess(t *testing.T) {
	testcases := map[string]struct {
		dir, dst string
	}{
		// NOTE(sean) the data sharing service uses URLs like:
		// https://storage.sagecontinuum.org/api/v1/data/{job}/sage-{task}-{tag}/{node}/{msg.timestamp}-{filename}
		//
		// It's a little a annoying to have that extra sage- bit... but for the sake of not changing URLs, I'm opting
		// to leave it and simply focus on fixing the job portion to match existing uploads.
		"default-sage": {
			dir: "node-000048b02d15bc7c/uploads/imagesampler-top/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c",
			dst: "node-data/sage/sage-imagesampler-top-0.2.5/000048b02d15bc7c/1638576647406523064-wow1.txt",
			// NOTE(sean) The filename comes from data generated by newTempDir.
		},
		"namespace": {
			dir: "node-000048b02d15bc7d/uploads/namespace/imagesampler-top/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c",
			dst: "node-data/namespace/sage-imagesampler-top-0.2.5/000048b02d15bc7d/1638576647406523064-wow4.txt",
		},
	}

	for name, tc := range testcases {
		t.Run(name, func(t *testing.T) {
			uploader := NewMockUploader()

			root := newTempDir(t)

			w := &Worker{
				Uploader: uploader,
			}

			job := Job{Root: root, Dir: tc.dir}

			if err := w.Process(job); err != nil {
				t.Fatal(err)
			}

			if !uploader.WasUploaded(filepath.Join(root, tc.dir, "data"), tc.dst) {
				t.Fatalf("missing upload\nsrc: %s\ndst: %s\n\n%v", tc.dir, tc.dst, uploader.uploads)
			}

			if !uploader.WasUploaded(filepath.Join(root, tc.dir, "meta"), tc.dst+".meta") {
				t.Fatalf("missing upload\nsrc: %s\ndst: %s", tc.dir, tc.dst)
			}
		})
	}
}

func TestParseUploadPath(t *testing.T) {
	testcases := map[string]struct {
		Dir  string
		Info UploadInfo
	}{
		"default": {
			Dir: "node-000048b02d15bc7c/uploads/imagesampler-top/0.2.5/1638576647406523064-8ca463ebcfab357f5d07c2529fb3939ddb4a5c32",
			Info: UploadInfo{
				Namespace: "sage",
				Name:      "imagesampler-top",
				Version:   "0.2.5",
				NodeID:    "000048b02d15bc7c",
			},
		},
		"namespace1": {
			Dir: "node-000048b02d15bc7d/uploads/Pluginctl/imagesampler-top/1.2.7/1638576647406523064-8ca463ebcfab357f5d07c2529fb3939ddb4a5c32",
			Info: UploadInfo{
				Namespace: "Pluginctl",
				Name:      "imagesampler-top",
				Version:   "1.2.7",
				NodeID:    "000048b02d15bc7d",
			},
		},
		"namespace2": {
			Dir: "node-00004cd98fc686c9/uploads/smoke-detector-1650456133/plugin-test-pipeline-0-2-8-1f055011/0.2.8/1649087778906567900-a31446e4291ac3a04a3c331e674252a63ee95604",
			Info: UploadInfo{
				Namespace: "smoke-detector-1650456133",
				Name:      "plugin-test-pipeline-0-2-8-1f055011",
				Version:   "0.2.8",
				NodeID:    "00004cd98fc686c9",
			},
		},
	}

	for name, tc := range testcases {
		t.Run(name, func(t *testing.T) {
			info, err := parseUploadPath(tc.Dir)
			if err != nil {
				t.Fatal(err)
			}
			assertStringsEqual(t, info.Namespace, tc.Info.Namespace)
			assertStringsEqual(t, info.Name, tc.Info.Name)
			assertStringsEqual(t, info.Version, tc.Info.Version)
			assertStringsEqual(t, info.NodeID, tc.Info.NodeID)
		})
	}
}

func assertStringsEqual(t *testing.T, got, want string) {
	if want != got {
		t.Fatalf("strings don't match. want: %q got: %q", want, got)
	}
}

func writeFile(name string, data []byte) error {
	if err := os.MkdirAll(filepath.Dir(name), 0o755); err != nil {
		return err
	}
	return os.WriteFile(name, data, 0o644)
}

func newTempDir(t *testing.T) string {
	root := filepath.Join(t.TempDir(), "data")

	if err := os.MkdirAll(root, 0o755); err != nil {
		panic(err)
	}

	items := map[string][]byte{
		"node-000048b02d15bc7c/uploads/imagesampler-top/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/data": []byte(`testing`),
		"node-000048b02d15bc7c/uploads/imagesampler-top/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/meta": []byte(`{"ts":1638576647406523064,"labels":{"filename":"wow1.txt"}}`),

		"node-000048b02d15bc7c/uploads/imagesampler-top/0.2.6/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/data": []byte("testing"),
		"node-000048b02d15bc7c/uploads/imagesampler-top/0.2.6/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/meta": []byte(`{"timestamp":1638576647406523064,"labels":{"filename":"wow2.txt"}}`),

		"node-000048b02d15bc7d/uploads/imagesampler-top/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/data": []byte("testing"),
		"node-000048b02d15bc7d/uploads/imagesampler-top/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/meta": []byte(`{"timestamp":1638576647406523064,"labels":{"filename":"wow3.txt"}}`),

		"node-000048b02d15bc7d/uploads/namespace/imagesampler-top/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/data": []byte("testing in namespace"),
		"node-000048b02d15bc7d/uploads/namespace/imagesampler-top/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/meta": []byte(`{"ts":1638576647406523064,"labels":{"filename":"wow4.txt"}}`),

		"node-000048b02d15bc7d/uploads/imagesampler-top/0.2.5/1638576647406523064-9801739daae44ec5293d4e1f53d3f4d2d426d91c/.partial/hello": []byte("!!! you should never see me !!!"),
	}

	for name, data := range items {
		if err := writeFile(filepath.Join(root, name), data); err != nil {
			panic(err)
		}
	}

	return root
}

type workerTestCase struct {
	Node      string
	Job       string
	Task      string
	Version   string
	Timestamp time.Time
	Filename  string
	Data      []byte
}

func (tc *workerTestCase) Dir() string {
	return filepath.Join("node-"+tc.Node, "uploads", tc.Task, tc.Version, fmt.Sprintf("%d-%s", tc.Timestamp.UnixNano(), tc.shastr()))
}

func (tc *workerTestCase) WriteFiles(root string) error {
	dir := tc.Dir()

	// write data file
	if err := tc.writeDataFile(filepath.Join(root, dir, "data")); err != nil {
		return err
	}

	// write meta file
	if err := tc.writeMetaFile(filepath.Join(root, dir, "meta")); err != nil {
		return err
	}

	return nil
}

func (tc *workerTestCase) writeDataFile(name string) error {
	if err := os.MkdirAll(filepath.Dir(name), 0o755); err != nil {
		return err
	}
	return os.WriteFile(name, tc.Data, 0o644)
}

func (tc *workerTestCase) writeMetaFile(name string) error {
	if err := os.MkdirAll(filepath.Dir(name), 0o755); err != nil {
		return err
	}

	meta := struct {
		Timestamp int64             `json:"ts"`
		Shasum    string            `json:"shasum"`
		Meta      map[string]string `json:"labels"`
	}{
		Timestamp: tc.Timestamp.UnixNano(),
		Shasum:    tc.shastr(),
		Meta: map[string]string{
			"filename": tc.Filename,
		},
	}

	f, err := os.Create(name)
	if err != nil {
		return err
	}
	defer f.Close()

	return json.NewEncoder(f).Encode(meta)
}

func (tc *workerTestCase) shastr() string {
	shasum := sha1.Sum(tc.Data)
	return hex.EncodeToString(shasum[:])
}

func randomWorkerTestCases(n int) []*workerTestCase {
	var testcases []*workerTestCase
	for i := 0; i < n; i++ {
		testcases = append(testcases, randomWorkerTestCase())
	}
	return testcases
}

func randomWorkerTestCase() *workerTestCase {
	return &workerTestCase{
		Timestamp: time.Now(),
		Node:      randomNode(),
		Task:      randomTask(),
		Filename:  randomFilename(),
		Version:   randomVersion(),
		Data:      randomData(),
	}
}

func randomNode() string {
	return fmt.Sprintf("%016x", rand.Intn(10))
}

func randomTask() string {
	return fmt.Sprintf("task-%d", rand.Intn(1000))
}

func randomFilename() string {
	return "filename.txt"
}

func randomVersion() string {
	return fmt.Sprintf("%d.%d.%d", rand.Intn(10), rand.Intn(10), rand.Intn(10))
}

func randomData() []byte {
	return []byte{1, 2, 3}
}

type pair struct{ src, dst string }

type MockUploader struct {
	Error   error
	uploads map[pair]bool
}

func NewMockUploader() *MockUploader {
	return &MockUploader{
		uploads: make(map[pair]bool),
	}
}

func (up *MockUploader) UploadFile(src, dst string, meta *MetaData) error {
	if up.Error != nil {
		return up.Error
	}
	up.uploads[pair{src, dst}] = true
	return nil
}

func (up *MockUploader) WasUploaded(src, dst string) bool {
	return up.uploads[pair{src, dst}]
}
